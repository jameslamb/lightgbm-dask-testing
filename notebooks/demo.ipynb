{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noticed-account",
   "metadata": {},
   "source": [
    "# LightGBM + Dask\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"./_img/lightgbm.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./_img/dask-horizontal.svg\" width=\"300\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "This notebook shows how to use `lightgbm.dask` to train a LightGBM model on data stored as a [Dask Array](https://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "To explore other topics in greater depth, see the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-incentive",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up a local Dask cluster\n",
    "\n",
    "Create a cluster with 3 workers. Since this is a `LocalCluster`, those workers are just 3 local processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dietary-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the dashboard: http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "n_workers = 3\n",
    "cluster = LocalCluster(n_workers=n_workers)\n",
    "\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)\n",
    "\n",
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-paper",
   "metadata": {},
   "source": [
    "Click the link above to view a diagnostic dashboard while you run the training code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-recommendation",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Get some training data\n",
    "\n",
    "This example uses `sklearn.datasets.make_regression()` to generate a dataset in `numpy` format, then uses `dask.Array.from_array()` to turn that into a Dask Array.\n",
    "\n",
    "That's just done for convenience. `lightgbm.dask` just expects that your data are Dask Arrays or Dask DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "billion-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=10000, random_state=42)\n",
    "dX = da.from_array(X, chunks=(1000, X.shape[1]))\n",
    "dy = da.from_array(y, chunks=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-terrace",
   "metadata": {},
   "source": [
    "Right now, the Dask Arrays `data` and `labels` are lazy. Before training, you can force the cluster to compute them by running `.persist()` and then wait for that computation to finish by `wait()`-ing on them.\n",
    "\n",
    "Doing this is optional, but it will make data loading a one-time cost so subsequent runs are fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metallic-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "dX = dX.persist()\n",
    "dy = dy.persist()\n",
    "_ = wait([dX, dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-central",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Train a model\n",
    "\n",
    "With the data set up on the workers, train a model. `lightgbm.dask.DaskLGBMRegressor` has an interface that tries to stay as close as possible to the non-Dask scikit-learn interface to LightGBM (`lightgbm.sklearn.LGBMRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animated-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/dask.py:530: UserWarning: Parameter n_jobs will be ignored.\n",
      "  _log_warning(f\"Parameter {param_alias} will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n",
      "[LightGBM] [Info] Trying to bind port 37155...\n",
      "[LightGBM] [Info] Binding port 37155 succeeded\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 200 milliseconds\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 260 milliseconds\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 338 milliseconds\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 439 milliseconds\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 570 milliseconds\n",
      "[LightGBM] [Info] Trying to bind port 39687...\n",
      "[LightGBM] [Info] Binding port 39687 succeeded\n",
      "[LightGBM] [Warning] Connecting to rank 2 failed, waiting for 200 milliseconds\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Trying to bind port 58167...\n",
      "[LightGBM] [Info] Binding port 58167 succeeded\n",
      "[LightGBM] [Info] Listening...\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Connected to rank 2\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Connected to rank 1\n",
      "[LightGBM] [Info] Local rank: 2, total number of machines: 3\n",
      "[LightGBM] [Info] Connected to rank 0\n",
      "[LightGBM] [Info] Connected to rank 2\n",
      "[LightGBM] [Info] Local rank: 1, total number of machines: 3\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Local rank: 0, total number of machines: 3\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of data points in the train set: 3000, number of used features: 100\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -0.239595\n",
      "[LightGBM] [Info] Start training from score -0.239595\n",
      "[LightGBM] [Info] Start training from score -0.239595\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Finished linking network in 0.709453 seconds\n",
      "[LightGBM] [Info] Finished linking network in 2.258702 seconds\n",
      "[LightGBM] [Info] Finished linking network in 1.730525 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DaskLGBMRegressor(client=&lt;Client: &#x27;tcp://127.0.0.1:39223&#x27; processes=3 threads=3, memory=6.79 GiB&gt;,\n",
       "                  max_depth=5, min_child_samples=1, num_threads=1,\n",
       "                  objective=&#x27;regression_l1&#x27;, time_out=120, tree_learner=&#x27;data&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DaskLGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>DaskLGBMRegressor(client=&lt;Client: &#x27;tcp://127.0.0.1:39223&#x27; processes=3 threads=3, memory=6.79 GiB&gt;,\n",
       "                  max_depth=5, min_child_samples=1, num_threads=1,\n",
       "                  objective=&#x27;regression_l1&#x27;, time_out=120, tree_learner=&#x27;data&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DaskLGBMRegressor(client=<Client: 'tcp://127.0.0.1:39223' processes=3 threads=3, memory=6.79 GiB>,\n",
       "                  max_depth=5, min_child_samples=1, num_threads=1,\n",
       "                  objective='regression_l1', time_out=120, tree_learner='data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm.dask import DaskLGBMRegressor\n",
    "\n",
    "dask_reg = DaskLGBMRegressor(\n",
    "    client=client,\n",
    "    max_depth=5,\n",
    "    objective=\"regression_l1\",\n",
    "    learning_rate=0.1,\n",
    "    tree_learner=\"data\",\n",
    "    n_estimators=100,\n",
    "    min_child_samples=1,\n",
    ")\n",
    "\n",
    "dask_reg.fit(\n",
    "    X=dX,\n",
    "    y=dy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-karen",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Evaluate the model\n",
    "\n",
    "The `.predict()` method takes in a Dask collection and returns a Dask Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "logical-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "dask.array<_predict_part, shape=(10000,), dtype=float32, chunksize=(1000,), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "preds = dask_reg.predict(dX)\n",
    "print(str(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-symposium",
   "metadata": {},
   "source": [
    "Before calculating the mean absolute error (MAE) of these predictions, compute some summary statistics on the target variable. This is necessary to understand what \"good\" values of MAE look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "peaceful-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0%: -627.63\n",
      "10.0%: -566.9\n",
      "25.0%: -515.82\n",
      "50.0%: -468.06\n",
      "75.0%: -452.54\n",
      "90.0%: -435.72\n",
      "99.0%: -419.1\n"
     ]
    }
   ],
   "source": [
    "p = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]\n",
    "dy_percentiles = da.percentile(dy, p).compute()\n",
    "\n",
    "for i, percentile in enumerate(p):\n",
    "    print(f\"{percentile * 100}%: {round(dy_percentiles[i], 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-clone",
   "metadata": {},
   "source": [
    "The metrics functions from `dask-ml` match those from `scikit-learn`, but take in and return Dask collections. You can use these functions to perform model evaluation without the evaluation data or predictions needing to be pulled down to the machine running this notebook. Pretty cool, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.59181626875831"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.metrics.regression import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(preds, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-teddy",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Learn more: https://lightgbm.readthedocs.io/en/latest/Python-API.html#dask-api.\n",
    "\n",
    "Ask a question, report a bug, or submit a feature request: https://github.com/microsoft/LightGBM/issues.\n",
    "\n",
    "Contribute: https://github.com/microsoft/LightGBM/issues?q=is%3Aissue+is%3Aopen+label%3Adask."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
