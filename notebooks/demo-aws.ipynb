{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "christian-tract",
   "metadata": {},
   "source": [
    "# LightGBM + Dask\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"./_img/lightgbm.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./_img/dask-horizontal.svg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"./_img/aws.svg\" width=\"150\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "This notebook shows how to use `lightgbm.dask` to train a LightGBM model on data stored as a [Dask Array](https://docs.dask.org/en/latest/array.html). It uses `FargateCluster` from [`dask-cloudprovider`](https://github.com/dask/dask-cloudprovider) to create a distributed cluster running on [AWS Fargate](https://aws.amazon.com/fargate/).\n",
    "\n",
    "To explore other topics in greater depth, see the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-costa",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Set up a Dask cluster on AWS Fargate\n",
    "\n",
    "Before running any of the code in the notebook, follow the instructions in [\"Test with a FargateCluster\"](../README.md##test-with-a-fargatecluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler and worker image: public.ecr.aws/w8s1c8b1/dask-lgb-test-4468592b-5204-4e3b-ad80-7c5ae698472a-cluster:1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../ecr-details.json\", \"r\") as f:\n",
    "    ecr_details = json.loads(f.read())\n",
    "\n",
    "CONTAINER_IMAGE = ecr_details[\"repository\"][\"repositoryUri\"] + \":1\"\n",
    "print(f\"scheduler and worker image: {CONTAINER_IMAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-mexico",
   "metadata": {},
   "source": [
    "Before proceeding, set up your AWS credentials. If you're unsure how to do this, see [the AWS docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heard-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-surface",
   "metadata": {},
   "source": [
    "Create a cluster with 3 workers. See https://cloudprovider.dask.org/en/latest/aws.html#dask_cloudprovider.aws.FargateCluster for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "starting-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Cluster.__del__ at 0x7f2546f11ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/cluster.py\", line 109, in __del__\n",
      "    if self.status != Status.closed:\n",
      "AttributeError: 'FargateCluster' object has no attribute 'status'\n",
      "Exception ignored in: <function Cluster.__del__ at 0x7f2546f11ee0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/cluster.py\", line 109, in __del__\n",
      "    if self.status != Status.closed:\n",
      "AttributeError: 'FargateCluster' object has no attribute 'status'\n",
      "/opt/conda/lib/python3.8/contextlib.py:120: UserWarning: Creating your cluster is taking a surprisingly long time. This is likely due to pending resources on AWS. Hang tight! \n",
      "  next(self.gen)\n",
      "/opt/conda/lib/python3.8/site-packages/distributed/client.py:1185: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+-------------+---------------+---------------+---------------+\n",
      "| Package     | client        | scheduler     | workers       |\n",
      "+-------------+---------------+---------------+---------------+\n",
      "| blosc       | 1.10.2        | 1.9.2         | 1.9.2         |\n",
      "| dask        | 2021.07.1     | 2021.07.2     | 2021.07.2     |\n",
      "| distributed | 2021.07.1     | 2021.07.2     | 2021.07.2     |\n",
      "| msgpack     | 1.0.2         | 1.0.0         | 1.0.0         |\n",
      "| pandas      | 1.3.1         | 1.0.5         | 1.0.5         |\n",
      "| python      | 3.8.6.final.0 | 3.8.0.final.0 | 3.8.0.final.0 |\n",
      "+-------------+---------------+---------------+---------------+\n",
      "Notes: \n",
      "-  msgpack: Variation is ok, as long as everything is above 0.6\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_cloudprovider.aws import FargateCluster\n",
    "\n",
    "n_workers = 3\n",
    "cluster = FargateCluster(\n",
    "    image=CONTAINER_IMAGE,\n",
    "    worker_cpu=512,\n",
    "    worker_mem=4096,\n",
    "    n_workers=n_workers,\n",
    "    fargate_use_private_ip=False,\n",
    "    scheduler_timeout=\"40 minutes\",\n",
    "    find_address_timeout=60 * 10,\n",
    "    worker_extra_args=[\"--nprocs=2\"]\n",
    ")\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "restricted-monitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the dashboard: http://44.242.164.141:8787/status\n"
     ]
    }
   ],
   "source": [
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-captain",
   "metadata": {},
   "source": [
    "Click the link above to view a diagnostic dashboard while you run the training code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-lloyd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Get some training data\n",
    "\n",
    "This example uses `sklearn.datasets.make_regression()` to generate a dataset in `numpy` format, then uses `dask.Array.from_array()` to turn that into a Dask Array.\n",
    "\n",
    "That's just done for convenience. `lightgbm.dask` just expects that your data are Dask Arrays or Dask DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collected-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=10000, random_state=42)\n",
    "dX = da.from_array(X, chunks=(1000, X.shape[1]))\n",
    "dy = da.from_array(y, chunks=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-jumping",
   "metadata": {},
   "source": [
    "Right now, the Dask Arrays `data` and `labels` are lazy. Before training, you can force the cluster to compute them by running `.persist()` and then wait for that computation to finish by `wait()`-ing on them.\n",
    "\n",
    "Doing this is optional, but it will make data loading a one-time cost so subsequent runs are fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "genuine-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait\n",
    "\n",
    "dX = dX.persist()\n",
    "dy = dy.persist()\n",
    "_ = wait([dX, dy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-equivalent",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Train a model\n",
    "\n",
    "With the data set up on the workers, train a model. `lightgbm.dask.DaskLGBMRegressor` has an interface that tries to stay as close as possible to the non-Dask scikit-learn interface to LightGBM (`lightgbm.sklearn.LGBMRegressor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "critical-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/dask.py:525: UserWarning: Parameter n_jobs will be ignored.\n",
      "  _log_warning(f\"Parameter {param_alias} will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding random open ports for workers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DaskLGBMRegressor(client=<Client: 'tcp://172.31.62.91:8786' processes=6 threads=6, memory=22.35 GiB>,\n",
       "                  max_depth=5, min_child_samples=1, n_estimators=10,\n",
       "                  num_threads=1, objective='regression_l1', time_out=120,\n",
       "                  tree_learner='data')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm.dask import DaskLGBMRegressor\n",
    "\n",
    "dask_reg = DaskLGBMRegressor(\n",
    "    client=client,\n",
    "    max_depth=5,\n",
    "    objective=\"regression_l1\",\n",
    "    learning_rate=0.1,\n",
    "    tree_learner=\"data\",\n",
    "    n_estimators=10,\n",
    "    min_child_samples=1,\n",
    ")\n",
    "\n",
    "dask_reg.fit(\n",
    "    X=dX,\n",
    "    y=dy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seven-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.31.63.34:37953,172.31.63.34:49763,172.31.5.137:43329,172.31.5.137:39591,172.31.2.25:48257,172.31.2.25:37347'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_reg.machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-aerospace",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Evaluate the model\n",
    "\n",
    "The `.predict()` method takes in a Dask collection and returns a Dask Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dask_reg.predict(dX)\n",
    "print(str(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-rebound",
   "metadata": {},
   "source": [
    "Before calculating the mean absolute error (MAE) of these predictions, compute some summary statistics on the target variable. This is necessary to understand what \"good\" values of MAE look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99]\n",
    "dy_percentiles = da.percentile(dy, p).compute()\n",
    "\n",
    "for i, percentile in enumerate(p):\n",
    "    print(f\"{percentile * 100}%: {round(dy_percentiles[i], 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-pledge",
   "metadata": {},
   "source": [
    "The metrics functions from `dask-ml` match those from `scikit-learn`, but take in and return Dask collections. You can use these functions to perform model evaluation without the evaluation data or predictions needing to be pulled down to the machine running this notebook. Pretty cool, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.metrics.regression import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(preds, dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-aviation",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Learn more: https://lightgbm.readthedocs.io/en/latest/Python-API.html#dask-api.\n",
    "\n",
    "Ask a question, report a bug, or submit a feature request: https://github.com/microsoft/LightGBM/issues.\n",
    "\n",
    "Contribute: https://github.com/microsoft/LightGBM/issues?q=is%3Aissue+is%3Aopen+label%3Adask."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
