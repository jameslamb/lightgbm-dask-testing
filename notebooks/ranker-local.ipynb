{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask LightGBMRanker\n",
    "\n",
    "This notebook tests `lightgbm.dask.LGBMRanker`, proposed in https://github.com/microsoft/LightGBM/pull/3708."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from lightgbm.dask import DaskLGBMRanker\n",
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38719 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the dashboard: http://127.0.0.1:38719/status\n"
     ]
    }
   ],
   "source": [
    "n_workers = 4\n",
    "cluster = LocalCluster(n_workers=n_workers)\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers)\n",
    "\n",
    "print(f\"View the dashboard: {cluster.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ranking(\n",
    "    n_samples=100,\n",
    "    n_features=20,\n",
    "    n_informative=5,\n",
    "    gmax=1,\n",
    "    random_gs=False,\n",
    "    avg_gs=10,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"Generate a learning-to-rank dataset - feature vectors grouped together with\n",
    "    integer-valued graded relevance scores. Replace this with a sklearn.datasets function\n",
    "    if ranking objective becomes supported in sklearn.datasets module.\"\"\"\n",
    "    rnd_generator = check_random_state(random_state)\n",
    "\n",
    "    y_vec, group_vec = np.empty((0,), dtype=int), np.empty((0,), dtype=int)\n",
    "    gid = 0\n",
    "\n",
    "    # build target, group ID vectors.\n",
    "    relvalues = range(gmax + 1)\n",
    "    while len(y_vec) < n_samples:\n",
    "        gsize = avg_gs if not random_gs else rnd_generator.poisson(avg_gs)\n",
    "        if not gsize:\n",
    "            continue\n",
    "\n",
    "        rel = rnd_generator.choice(relvalues, size=gsize, replace=True)\n",
    "        y_vec = np.append(y_vec, rel)\n",
    "        group_vec = np.append(group_vec, [gid] * gsize)\n",
    "        gid += 1\n",
    "\n",
    "    y_vec, group_vec = y_vec[0:n_samples], group_vec[0:n_samples]\n",
    "\n",
    "    # build feature data, X. Transform first few into informative features.\n",
    "    n_informative = max(min(n_features, n_informative), 0)\n",
    "    x_grid = np.linspace(0, stop=1, num=gmax + 2)\n",
    "    X = rnd_generator.uniform(size=(n_samples, n_features))\n",
    "\n",
    "    # make first n_informative features values bucketed according to relevance scores.\n",
    "    def bucket_fn(z):\n",
    "        return rnd_generator.uniform(x_grid[z], high=x_grid[z + 1])\n",
    "\n",
    "    for j in range(n_informative):\n",
    "        bias, coef = rnd_generator.normal(size=2)\n",
    "        X[:, j] = bias + coef * np.apply_along_axis(bucket_fn, axis=0, arr=y_vec)\n",
    "\n",
    "    return X, y_vec, group_vec\n",
    "\n",
    "\n",
    "def _create_ranking_data(n_samples=100, output=\"array\", chunk_size=50):\n",
    "    X, y, g = _make_ranking(n_samples=n_samples, random_state=42)\n",
    "    rnd = np.random.RandomState(42)\n",
    "    w = rnd.rand(X.shape[0]) * 0.01\n",
    "    g_rle = np.array([sum([1 for _ in grp]) for _, grp in itertools.groupby(g)])\n",
    "\n",
    "    if output == \"dataframe\":\n",
    "\n",
    "        # add target, weight, and group to DataFrame so that partitions abide by group boundaries.\n",
    "        X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "        X = X_df.copy()\n",
    "        X_df = X_df.assign(y=y, g=g, w=w)\n",
    "\n",
    "        # set_index ensures partitions are based on group id. See https://bit.ly/3pAWyNw.\n",
    "        X_df.set_index(\"g\", inplace=True)\n",
    "        dX = dd.from_pandas(X_df, chunksize=chunk_size)\n",
    "\n",
    "        # separate target, weight from features.\n",
    "        dy = dX[\"y\"]\n",
    "        dw = dX[\"w\"]\n",
    "        dX = dX.drop(columns=[\"y\", \"w\"])\n",
    "        dg = dX.index.to_series()\n",
    "\n",
    "        # encode group identifiers into run-length encoding, the format LightGBMRanker is expecting\n",
    "        # so that within each partition, sum(g) = n_samples.\n",
    "        dg = dg.map_partitions(lambda p: p.groupby(\"g\", sort=False).apply(lambda z: z.shape[0]))\n",
    "\n",
    "    elif output == \"array\":\n",
    "\n",
    "        # ranking arrays: one chunk per group. Each chunk must include all columns.\n",
    "        p = X.shape[1]\n",
    "        dX, dy, dw, dg = list(), list(), list(), list()\n",
    "        for g_idx, rhs in enumerate(np.cumsum(g_rle)):\n",
    "            lhs = rhs - g_rle[g_idx]\n",
    "            dX.append(da.from_array(X[lhs:rhs, :], chunks=(rhs - lhs, p)))\n",
    "            dy.append(da.from_array(y[lhs:rhs]))\n",
    "            dw.append(da.from_array(w[lhs:rhs]))\n",
    "            dg.append(da.from_array(np.array([g_rle[g_idx]])))\n",
    "\n",
    "        dX = da.concatenate(dX, axis=0)\n",
    "        dy = da.concatenate(dy, axis=0)\n",
    "        dw = da.concatenate(dw, axis=0)\n",
    "        dg = da.concatenate(dg, axis=0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"ranking data creation only supported for Dask arrays and dataframes\")\n",
    "\n",
    "    return X, y, w, g_rle, dX, dy, dw, dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, w, g, dX, dy, dw, dg = _create_ranking_data(output=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter tree_learner not set or set to incorrect value (None), using \"data\" as default\n"
     ]
    }
   ],
   "source": [
    "listen_port = 12410\n",
    "\n",
    "dask_ranker = DaskLGBMRanker(\n",
    "    time_out=5, local_listen_port=listen_port, seed=42, min_child_samples=1\n",
    ")\n",
    "\n",
    "dask_ranker = dask_ranker.fit(X=dX, y=dy, sample_weight=dw, group=dg, client=client)\n",
    "rnkvec_dask = dask_ranker.predict(dX)\n",
    "rnkvec_dask = rnkvec_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.61911428,  1.34558111, -1.68706133, -1.6254889 , -1.62548888,\n",
       "        2.1857188 , -1.59656968, -1.62548889, -1.61626712,  2.78163879,\n",
       "       -1.60519821, -1.62266898, -1.76722149, -1.60593613,  1.31288066,\n",
       "       -1.61377047,  1.59345141,  1.73398405,  2.09383409, -1.76648355,\n",
       "        2.64820997, -1.75394921,  1.3018359 ,  2.64820998,  1.32681614,\n",
       "        1.31383015,  1.73398404,  1.33805625,  2.12685499,  2.17598738,\n",
       "       -1.60779518, -1.59997695,  1.66347386,  2.07799638,  2.7816388 ,\n",
       "       -1.6690408 ,  1.56922532, -1.60071491, -1.75958592, -1.79631722,\n",
       "       -1.59186463, -1.70317437,  2.16717095,  2.61456174,  2.8584333 ,\n",
       "        1.297471  ,  1.34986058, -1.67453332,  2.64820998,  2.09903914,\n",
       "       -1.59649273,  2.09708282, -1.67861995,  2.54080954, -1.58664337,\n",
       "        2.10144774,  1.59922552, -1.59649959, -1.59656969, -1.58942456,\n",
       "       -1.60484607, -1.62548889, -1.66474169, -1.68591056, -1.68418729,\n",
       "        2.08540358,  2.06515072, -1.66789002,  1.5944009 ,  2.06515072,\n",
       "        1.29747099,  1.32606199, -1.60473661,  1.808978  , -1.62181847,\n",
       "        2.64820998,  1.31288066,  1.297471  , -1.63927288,  1.78957653,\n",
       "       -1.63289821,  2.78468113, -1.61626712,  1.33118104, -1.60650183,\n",
       "       -1.62151823,  1.83539281, -1.64187498,  1.32681614,  1.3210606 ,\n",
       "        1.61199927,  1.82422315,  2.61760406,  2.09708282,  2.64820998,\n",
       "        2.54385187,  1.80143528,  2.78163879,  2.85843331, -1.60431607])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnkvec_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ranker = LGBMRanker(seed=42, min_child_samples=1)\n",
    "local_ranker.fit(X, y, sample_weight=w, group=g)\n",
    "rnkvec_local = local_ranker.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8598233007392299"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distributed ranker should be able to rank decently well.\n",
    "dcor = spearmanr(rnkvec_dask, y).correlation\n",
    "assert dcor > 0.6\n",
    "dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007107967896998746\n"
     ]
    }
   ],
   "source": [
    "# relative difference between distributed ranker and local ranker spearman corr should be small.\n",
    "lcor = spearmanr(rnkvec_local, y).correlation\n",
    "print(np.abs(dcor - lcor))\n",
    "assert np.abs(dcor - lcor) < 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
